# Evaluation Metrics

## Precision
##### Definition: 
Indicates the proportion of true positive predictions among all positive predictions.
##### Calculation: 
Precision = (TP)/(TP+FP)

## Recall (Sensitivity)
##### Definition: 
 Reflects the proportion of actual positives correctly identified
##### Calculation: 
Recall = (TP) / (TP+FN)

## F1 score
##### Definition: 
The harmonic mean of Precision and Recall.
##### Calculation: 
F1 = 2 * (Precision * Recall) / (Precision + Recall)

# Using the Scripts
Follow the function definition, and use them as helper functions that would be imported to your code
example: "

## Example Usage 

Call `f1(tp, tn, fp, fn)` in a python script



